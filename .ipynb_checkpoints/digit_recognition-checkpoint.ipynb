{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits['data']\n",
    "y = digits['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_weight(incoming_conn, outgoing_conn):\n",
    "    epsilon_init = 0.12\n",
    "    weight = np.random.rand(outgoing_conn, incoming_conn + 1) * 2 * epsilon_init - epsilon_init\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    sigmoid_ = sigmoid(z)\n",
    "    gradient = sigmoid_ * (1 - sigmoid_)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    A1 = np.hstack((np.ones((m, 1)), X))\n",
    "    Z2 = A1 @ theta1.T\n",
    "    A2 = np.c_[np.ones((Z2.shape[0], 1)), sigmoid(Z2)]\n",
    "    Z3 = A2 @ theta2.T\n",
    "    A3 = H = sigmoid(Z3)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_targets(y, num_labels=10):\n",
    "    m = y.shape[0]\n",
    "    I = np.eye(10)\n",
    "    Y = np.zeros((m, 10))\n",
    "    \n",
    "    for i in range(m):\n",
    "        Y[i, :] = I[y[i], :]\n",
    "        \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, Y, theta1, theta2, num_labels, lambda_=0.3):\n",
    "    m = X.shape[0]\n",
    "    H = get_predictions(X, theta1, theta2)\n",
    "    penalty = (lambda_ / (2 * m)) * (np.sum(theta1[:, 1:]**2) + np.sum(theta2[:, 1:]**2))\n",
    "    cost = np.sum( (-Y * np.log(H)) - ((1 - Y) * np.log(1 - H)) ) / m\n",
    "    cost += penalty\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(X, Y, theta1, theta2, lambda_):\n",
    "    m = X.shape[0]\n",
    "    A1 = np.hstack((np.ones((m, 1)), X))\n",
    "    Z2 = A1 @ theta1.T\n",
    "    A2 = np.c_[np.ones((Z2.shape[0], 1)), sigmoid(Z2)]\n",
    "    Z3 = A2 @ theta2.T\n",
    "    A3 = H = sigmoid(Z3)\n",
    "\n",
    "    sigma3 = H - Y\n",
    "    sigma2 = (sigma3 @ theta2) * sigmoid_gradient(np.c_[np.ones(Z2.shape[0]), Z2])\n",
    "    sigma2 = sigma2[:, 1:]\n",
    "\n",
    "    delta1 = sigma2.transpose() @ A1\n",
    "    delta2 = sigma3.transpose() @ A2\n",
    "\n",
    "    theta1_grad = (delta1 / m) + (lambda_ / m) *  np.c_[np.zeros(theta1.shape[0]), theta1[:, 1:]]\n",
    "    theta2_grad = (delta2 / m) + (lambda_ / m) *  np.c_[np.zeros(theta2.shape[0]), theta2[:, 1:]]\n",
    "    return theta1_grad, theta2_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = get_random_weight(X.shape[1], 120)\n",
    "theta2 = get_random_weight(120, 10)\n",
    "Y = vectorize_targets(y_train)\n",
    "alpha = 0.03\n",
    "cost_history = []\n",
    "\n",
    "for i in range(500):\n",
    "    cost = cost_function(X_train, Y, theta1, theta2, 1)\n",
    "    cost_history.append(cost)\n",
    "    theta1_grad, theta2_grad = get_gradients(X_train, Y, theta1, theta2, 1)\n",
    "    theta1 = theta1 - alpha * theta1_grad\n",
    "    theta2 = theta2 - alpha * theta2_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = np.argmax(get_predictions(X_test, theta1, theta2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of right predictions in test test: 94.22222222222223\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of right predictions in test test: {}\".format((sum(predictions_test == y_test) * 100) / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = np.argmax(get_predictions(X_train, theta1, theta2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of right predictions in train set: 95.02598366740905\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of right predictions in train set: {}\".format((sum(predictions_train == y_train) * 100) / len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train_data.pickle', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train_data['features'][1797: 1847]\n",
    "test_target = train_data['targets'][1797:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_unseen_test = np.argmax(get_predictions(test, theta1, theta2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of right predictions in unseen data set: 6.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of right predictions in unseen data set: {}\".format((sum(predictions_unseen_test == test_target) * 100) / len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(train_data['features'], train_data['targets'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_hidden_layer_size = 80\n",
    "theta1 = get_random_weight(train_data['features'].shape[1], first_hidden_layer_size)\n",
    "theta2 = get_random_weight(first_hidden_layer_size, 10)\n",
    "Y = vectorize_targets(train_data['targets'])\n",
    "alpha = 0.03\n",
    "cost_history = []\n",
    "\n",
    "for i in range(500):\n",
    "    cost = cost_function(train_data['features'], Y, theta1, theta2, 1)\n",
    "    cost_history.append(cost)\n",
    "    theta1_grad, theta2_grad = get_gradients(train_data['features'], Y, theta1, theta2, 1)\n",
    "    theta1 = theta1 - alpha * theta1_grad\n",
    "    theta2 = theta2 - alpha * theta2_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of right predictions in unseen data set: 68.0\n",
      "Percentage of right predictions in test test: 98.0\n",
      "Percentage of right predictions in train set: 96.21380846325167\n"
     ]
    }
   ],
   "source": [
    "predictions_unseen_test = np.argmax(get_predictions(test, theta1, theta2), axis=1)\n",
    "predictions_test = np.argmax(get_predictions(X_test, theta1, theta2), axis=1)\n",
    "predictions_train = np.argmax(get_predictions(X_train, theta1, theta2), axis=1)\n",
    "print(\"Percentage of right predictions in unseen data set: {}\".format((sum(predictions_unseen_test == test_target) * 100) / len(test_target)))\n",
    "print(\"Percentage of right predictions in test test: {}\".format((sum(predictions_test == y_test) * 100) / len(y_test)))\n",
    "print(\"Percentage of right predictions in train set: {}\".format((sum(predictions_train == y_train) * 100) / len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a cross validation to find optional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optional_thetas(X, y, alpha, hidden_layer_node_count):\n",
    "    feature_count = X.shape[0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    theta1 = get_random_weight(feature_count, hidden_layer_node_count)\n",
    "    theta2 = get_random_weight(hidden_layer_node_count, 10)\n",
    "    Y = vectorize_targets(y)\n",
    "\n",
    "    for i in range(500):\n",
    "        cost = cost_function(X, Y, theta1, theta2, 1)\n",
    "        cost_history.append(cost)\n",
    "        theta1_grad, theta2_grad = get_gradients(train_data['features'], Y, theta1, theta2, 1)\n",
    "        theta1 = theta1 - alpha * theta1_grad\n",
    "        theta2 = theta2 - alpha * theta2_grad\n",
    "    \n",
    "    return theta1, theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_right_prediction_percentage(X, y, theta1, theta2):\n",
    "    predictions = np.argmax(get_predictions(X, theta1, theta2), axis=1)\n",
    "    return sum(predictions == y) * 100 / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimum_parameters(X, y, parameters: dict):\n",
    "    results = []\n",
    "\n",
    "    for alpha in parameters['alpha_values']:\n",
    "        for hidden_layer_node_count in parameters['hidden_layer_node_counts']:\n",
    "            theta1, theta2 = get_optional_thetas(X, y, alpha, hidden_layer_node_count)\n",
    "            results.append({\n",
    "                'alpha': alpha,\n",
    "                'hidden_layer_node_count': hidden_layer_node_count,\n",
    "                'percentage': get_right_prediction_percentage(X, y, theta1, theta2)\n",
    "            })\n",
    "    \n",
    "    percentages = [result['percentage'] for result in results]\n",
    "    return params[np.argmax(percentages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'alpha_values': [0.03, 0.01, 0.1, 0.3, 1],\n",
    "    'hidden_layer_node_counts': range(60, 100, 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_data['features'], train_data['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "optimum_parameters = get_optimum_parameters(X, y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.3, 'hidden_layer_node_count': 95, 'percentage': 99.51298701298701}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
